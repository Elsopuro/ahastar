\section{Hierarchical planning}
Given a suitable graph abstraction, we can once more turn our attention back to agent planning. Our approach is very straightforward extension of the ideas we introduced with AA*; to begin computing we require first that our agent is assigned capability and size attributes and a pair of initial and start nodes which are valid pathfinding areas. 
We use this information to identify the local cluster (this step is described earlier) and use it to establish our location in the abstract graph. In the event that both the start and goal nodes are located in the same cluster, we use AA* to find a solution directly. To avoid cases where the start and goal are lin close proximity but cannot be reached without significant search effort (for instance, on opposite sides of a maze wall) we limit this search to the cluster area. If the search fails, or if the start and goal are not in the same cluster initially, we insert into the abstract graph two new temporary nodes (which we later remove when we are finished) to represent the start and goal. \\ \newline
Next, we use AA* to determine the distance to each transition point from the initial states in both the start and goal clusters. We use the results of each search to connect the new temporary nodes to the rest of the abstract graph so that we can compute a high-level plan. This phase involves $n+m$ searches in total, corresponding to the number of combined transitions in the start and goal clusters.\\ \newline
Once the start and goal are inserted, we use a variation on A* to compute a plan. Our extension is simple: before adding any node to the open list, first evaluate the annotations of the edge connecting it to our current location and determine if the corridor is traversable or not given our agent's size and capability.
If the search is successful we can take the result, and, if immediate execution is not necessary, we are finished. Otherwise, we refine the plan by performing a number of small searches between each pair of nodes along the abstract optimal path. We can optionally skip this step if we cache the result of our previous searches while building the abstraction, in another classic case of performance vs space tradeoff. Caching is not required of course but as we will see, it can speed up the total search time by limiting our effort to localised insertion and planning in the abstract space. \\ \newline 
This completes the description of our final algorithm: Annotated Hierarchical A* (AHA for short).
